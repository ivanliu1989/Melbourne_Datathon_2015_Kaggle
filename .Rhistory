data("iris")
# this is a little tweak so that things line up nicely later on
iris$Species <- factor(iris$Species,
levels = c("versicolor","virginica","setosa"))
head(iris)
round(cor(iris[,1:4]), 2)
pc <- princomp(iris[,1:4], cor=TRUE, scores=TRUE)
summary(pc)
plot(pc,type="lines")
biplot(pc)
library(rgl)
plot3d(pc$scores[,1:3], col=iris$Species)
text3d(pc$scores[,1:3],texts=rownames(iris))
text3d(pc$loadings[,1:3], texts=rownames(pc$loadings), col="red")
coords <- NULL
for (i in 1:nrow(pc$loadings)) {
coords <- rbind(coords, rbind(c(0,0,0),pc$loadings[i,1:3]))
}
lines3d(coords, col="red", lwd=4)
set.seed(42)
cl <- kmeans(iris[,1:4],3)
iris$cluster <- as.factor(cl$cluster)
plot3d(pc$scores[,1:3], col=iris$cluster, main="k-means clusters")
setwd('/Users/ivanliu/Google Drive/Melbourne Datathon/Melbourne_Datathon_2015_Kaggle')
rm(list=ls()); gc()
library(xgboost);library(pROC);library(caret)
load('data/9_train_validation_test_20151105.RData');ls()
# c(101183757,101183885,101184013) - last 3 event
# c(101150834,101153072,101149398) - validation
# c(101093076,101093194,101093312)
# c(101128387,101150348,101152275)
# c(101149870,101150716,101153308)
### Test
# train <- total
### Validation
training <- train[!train$EVENT_ID %in% c(101149870,101150716,101153308),]
testing <- train[train$EVENT_ID %in% c(101149870,101150716,101153308),]
dim(training); dim(testing)
training$flag_class <- ifelse(training$flag_class == 'Y', 1, 0)
feat <- colnames(training)[c(3:56,58:61)]
setwd('/Users/ivanliu/Google Drive/Melbourne Datathon/Melbourne_Datathon_2015_Kaggle')
rm(list=ls()); gc()
library(xgboost);library(pROC);library(caret)
load('data/9_train_validation_test_20151105.RData');ls()
# c(101183757,101183885,101184013) - last 3 event
# c(101150834,101153072,101149398) - validation
# c(101093076,101093194,101093312)
# c(101128387,101150348,101152275)
# c(101149870,101150716,101153308)
### Test
# train <- total
### Validation
training <- train[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
testing <- train[train$EVENT_ID %in% c(101183757,101183885,101184013),]
dim(training); dim(testing)
training$flag_class <- ifelse(training$flag_class == 'Y', 1, 0)
feat <- colnames(training)[c(3:56,58:61)]
bst <-
xgboost(
data = as.matrix(training[,feat]), label = training$flag_class, max.depth = 6, num_parallel_tree = 500, subsample = 0.5, colsample_bytree =
0.5, nround = 1, objective = "binary:logistic"
)
#--------------------basic prediction using xgboost--------------
val <- validation
p <- predict(bst, as.matrix(val[,feat]))
# p <- predict(bst, as.matrix(train[,feat]))
val$Y <- p
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y#(val$Y - 0.5) * 2
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, mean, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$INVEST_PERCENT);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$Y);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
p <- predict(bst, as.matrix(train[,feat]))
val$Y <- p
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y#(val$Y - 0.5) * 2
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, mean, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$INVEST_PERCENT);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$Y);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
val <- testing
p <- predict(bst, as.matrix(val[,feat]))
# p <- predict(bst, as.matrix(train[,feat]))
val$Y <- p
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y#(val$Y - 0.5) * 2
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, mean, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$INVEST_PERCENT);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$Y);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
# val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y#(val$Y - 0.5) * 2
val <- testing
p <- predict(bst, as.matrix(val[,feat]))
# p <- predict(bst, as.matrix(train[,feat]))
val$Y <- p
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
# val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y#(val$Y - 0.5) * 2
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, mean, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$INVEST_PERCENT);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$Y);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
val <- testing
p <- predict(bst, as.matrix(val[,feat]))
# p <- predict(bst, as.matrix(train[,feat]))
val$Y <- p
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * (val$Y - 0.5) * 2
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, mean, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$INVEST_PERCENT);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$Y);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
setwd('/Users/ivanliu/Google Drive/Melbourne Datathon/Melbourne_Datathon_2015_Kaggle')
rm(list=ls()); gc()
library(h2o);library(pROC);library(doMC)
load('data/9_train_validation_test_20151106.RData');ls()
# c(101183757,101183885,101184013) - last 3 event
# c(101150834,101153072,101149398) - validation
# c(101093076,101093194,101093312)
# c(101128387,101150348,101152275)
# c(101149870,101150716,101153308)
################
### Register ###
################
set.seed(8)
localH2O <- h2o.init(ip = 'localhost', port = 54321, max_mem_size = '12g')
train$flag_class <- as.factor(train$flag_class); levels(train$flag_class) <- c(0,1)
val_class <- validation$flag_class
validation$flag_class <- as.factor(validation$flag_class); levels(validation$flag_class) <- c(0,1)
total$flag_class <- as.factor(total$flag_class); levels(total$flag_class) <- c(0,1)
######################
### Feature Select ###
######################
training <- train[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
testing <- train[train$EVENT_ID %in% c(101183757,101183885,101184013),]
dim(training); dim(testing)
# total_df <- as.h2o(localH2O, total)
train_df <- as.h2o(localH2O, training) # train
validation_df <- as.h2o(localH2O, validation)
test_df <- as.h2o(localH2O, testing) # test
colnames(train_df)
independent <- c(colnames(train_df[,3:(ncol(train_df)-2)]))#'INVEST','win_hist','EVENT_COUNT',
dependent <- "flag_class"
# independent <- independent[
# !independent %in%
# c('MAX_BET_SIZE_OUTPLAY_L',
# 'AVG_PLACED_TAKEN_TIME_INPLAY',
# 'STDEV_BET_SIZE_OUTPLAY',
# 'AVG_BET_SIZE_OUTPLAY',
# 'BL_DIFF_STDEV_BET_SIZE_OUT',
# 'KURT_PLACED_TAKEN_TIME_INPLAY',
# 'NET_PROFIT_INPLAY',
# 'STDEV_BET_SIZE_INPLAY',
# 'TRANSACTION_COUNT_OUTPLAY_L',
# 'SKEW_PLACED_TAKEN_TIME_INPLAY',
# 'TRANSACTION_COUNT_INPLAY',
# 'BL_DIFF_TRANSACTION_COUNT_IN',
# 'INPLAY_RATIO',
# 'win_hist')]
##############
### Models ###
##############
# perf <- 0
# for(i in 1:100){
#
#     fit <- h2o.gbm(
#         y = dependent, x = independent, data = train_df, #train_df | total_df
#         n.trees = 200, interaction.depth = 8, n.minobsinnode = 1,
#         shrinkage = 0.25, distribution = "bernoulli", n.bins = 20,  #AUTO
#         importance = F
#     )
#
#     d0 <- 256; d1 <- 0.01; d2 <- 0.5; d3 <- 0.5
#     fit <-
#         h2o.deeplearning(
#             y = dependent, x = independent, data = total_df, classification = T,
#             activation = "RectifierWithDropout",#TanhWithDropout "RectifierWithDropout" nfolds = 5,
#             hidden = c(256,256,256), adaptive_rate = T, rho = 0.99,
#             epsilon = 1e-4, rate = 0.01, rate_decay = 0.9, # rate_annealing = ,
#             momentum_start = 0.5, momentum_stable = 0.99, # momentum_ramp
#             nesterov_accelerated_gradient = T, input_dropout_ratio = 0.5, hidden_dropout_ratios = c(0.5,0.5,0.5),
#             l2 = 3e-6, max_w2 = 4, #Rect
#             loss = 'CrossEntropy', classification_stop = -1,
#             diagnostics = T, variable_importances = T, ignore_const_cols = T,
#             force_load_balance = T, replicate_training_data = T, shuffle_training_data = T,
#             sparse = F, epochs = 5 #, reproducible, score_validation_sampling seed = 8,
#         )
#     d0 <- 100; d1 <- 10; d2 <- 8; d3 <- 0.8
fit <-
h2o.randomForest(
y = dependent, x = independent, data = train_df, #train_df | total_df #validation_frame
ntree = 100, depth = 10, mtries = 8, sample.rate = 0.8, nbins = 10, importance = F
)
#     fit <-
#         h2o.naiveBayes(
#             y = dependent, x = independent, data = train_df, laplace = 0
#         )
#
#     fit <-
#         h2o.glm(
#             y = dependent, x = independent, data = total_df, #train_df | total_df
#             family = 'binomial', link = 'logit',alpha = 0.5, # 1 lasso 0 ridge
#             lambda = 1e-08, lambda_search = T, nlambda = 12, lambda.min.ratio = 0.1,
#             strong_rules = T, standardize = T, intercept = F, use_all_factor_levels = F,
#             epsilon = 1e-4, iter.max = 100, higher_accuracy = T, disable_line_search = F
#         )
##################
### Prediction ###
##################
# val <- validation; pred <- h2o.predict(object = fit, newdata = validation_df)
val <- testing; pred <- h2o.predict(object = fit, newdata = test_df)
val <- cbind(val, as.data.frame(pred[,3])) #X1=pred[,3]
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$X1#(val$X1 - 0.5) * 2
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, sum, na.rm=F)
pred_fin2 <- aggregate(X1 ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
# With a roc object:
rocobj1 <- roc(v$PRED_PROFIT_LOSS_3, v$INVEST_PERCENT);rocobj1
perf_new1 <- auc(rocobj1, partial.auc = c(1, .8), partial.auc.focus = "se", partial.auc.correct = TRUE)
perf_new1
rocobj2 <- roc(v$PRED_PROFIT_LOSS_3, v$X1);rocobj2
perf_new2 <- auc(rocobj2, partial.auc = c(1, .8), partial.auc.focus = "se", partial.auc.correct = TRUE)
perf_new2
setwd('/Users/ivanliu/Google Drive/Melbourne Datathon/Melbourne_Datathon_2015_Kaggle')
rm(list=ls()); gc()
library(xgboost);library(pROC);library(caret)
load('data/9_train_validation_test_20151105.RData');ls()
# c(101183757,101183885,101184013) - last 3 event
# c(101150834,101153072,101149398) - validation
# c(101093076,101093194,101093312)
# c(101128387,101150348,101152275)
# c(101149870,101150716,101153308)
### Test
# train <- total
### Validation
training <- train[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
testing <- train[train$EVENT_ID %in% c(101183757,101183885,101184013),]
dim(training); dim(testing)
training$flag_class <- ifelse(training$flag_class == 'Y', 1, 0)
feat <- colnames(training)[c(3:56,58:61)]
# feat <- feat[
#     !feat %in%
#         c('STDEV_BET_SIZE_OUTPLAY_L','BL_DIFF_TRANSACTION_COUNT_OUT','TRANSACTION_COUNT_OUTPLAY_L',
#           'BL_DIFF_STDEV_BET_SIZE_OUT','BL_DIFF_MIN_BET_SIZE_OUT','AVG_TAKEN_HOUR_INPLAY')]
# for(d in c(0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12,0.13,0.14,0.15)){
# print (paste0('Parameter: ', d))
#-------------Basic Training using XGBoost-----------------
#     bst <-
#         xgboost(  # c(3:22,42,43,47:56) | 3:56
#             data = as.matrix(training[,feat]), label = training$flag_class, max.depth = 6, eta = 0.15, nround = 500, maximize = F, #500,0.15
#             nthread = 4, objective = "binary:logistic", verbose = 1, early.stop.round = 10, print.every.n = 10, metrics = 'auc'
#         )
bst <-
xgboost(
data = as.matrix(training[,feat]), label = training$flag_class, max.depth = 8, num_parallel_tree = 100, subsample = 0.8, colsample_bytree =
0.8, nround = 1, objective = "binary:logistic"
)
#--------------------basic prediction using xgboost--------------
val <- validation
val <- testing
p <- predict(bst, as.matrix(val[,feat]))
# p <- predict(bst, as.matrix(train[,feat]))
val$Y <- p
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y#(val$Y - 0.5) * 2
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, mean, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$INVEST_PERCENT);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$Y);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
val <- validation
# val <- testing
p <- predict(bst, as.matrix(val[,feat]))
# p <- predict(bst, as.matrix(train[,feat]))
val$Y <- p
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y#(val$Y - 0.5) * 2
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, mean, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$INVEST_PERCENT);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$Y);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
bst <-
xgboost(
data = as.matrix(training[,feat]), label = training$flag_class, max.depth = 8, num_parallel_tree = 100, subsample = 0.5, colsample_bytree =
0.5, nround = 1, objective = "binary:logistic"
)
#--------------------basic prediction using xgboost--------------
val <- validation
# val <- testing
p <- predict(bst, as.matrix(val[,feat]))
# p <- predict(bst, as.matrix(train[,feat]))
val$Y <- p
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y#(val$Y - 0.5) * 2
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, mean, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$INVEST_PERCENT);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$Y);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
bst <-
xgboost(
data = as.matrix(training[,feat]), label = training$flag_class, max.depth = 9, num_parallel_tree = 100, subsample = 0.5, colsample_bytree =
0.5, nround = 1, objective = "binary:logistic"
)
#--------------------basic prediction using xgboost--------------
val <- validation
# val <- testing
p <- predict(bst, as.matrix(val[,feat]))
# p <- predict(bst, as.matrix(train[,feat]))
val$Y <- p
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y#(val$Y - 0.5) * 2
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, mean, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$INVEST_PERCENT);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$Y);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
bst <-
xgboost(
data = as.matrix(training[,feat]), label = training$flag_class, max.depth = 9, num_parallel_tree = 150, subsample = 0.5, colsample_bytree =
0.5, nround = 1, objective = "binary:logistic"
)
#--------------------basic prediction using xgboost--------------
val <- validation
# val <- testing
p <- predict(bst, as.matrix(val[,feat]))
# p <- predict(bst, as.matrix(train[,feat]))
val$Y <- p
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y#(val$Y - 0.5) * 2
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, mean, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$INVEST_PERCENT);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$Y);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
bst <-
xgboost(
data = as.matrix(training[,feat]), label = training$flag_class, max.depth = 10, num_parallel_tree = 150, subsample = 0.5, colsample_bytree =
0.5, nround = 1, objective = "binary:logistic"
)
#--------------------basic prediction using xgboost--------------
val <- validation
# val <- testing
p <- predict(bst, as.matrix(val[,feat]))
# p <- predict(bst, as.matrix(train[,feat]))
val$Y <- p
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y#(val$Y - 0.5) * 2
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, mean, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$INVEST_PERCENT);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$Y);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
setwd('/Users/ivanliu/Google Drive/Melbourne Datathon/Melbourne_Datathon_2015_Kaggle')
rm(list = ls()); gc()
library(xgboost);library(pROC);library(caret)
load('data/9_train_validation_test_20151106.RData');ls()
events <- unique(total$EVENT_ID)
for (i in 1:(length(events) - 2)) {
print(paste0('Round ', i, ' | Subsetting without event: ', events[i:(i + 2)]))
train <- total
training <- train[!train$EVENT_ID %in% events[i:(i + 2)],]
training$flag_class <- ifelse(training$flag_class == 'Y', 1, 0)
feat <- colnames(training)[c(3:57)]
#-------------Basic Training using XGBoost-----------------
#     bst <-
#         xgboost(
#             data = as.matrix(training[,feat]), label = training$flag_class, max.depth = 6, eta = 0.02, nround = 1200, maximize = F, #500,0.15
#             nthread = 4, objective = "binary:logistic", metrics = 'auc', verbose = 0
#         )
bst <-
xgboost(
data = as.matrix(training[,feat]), label = training$flag_class, max.depth = 9, num_parallel_tree = 150, subsample = 0.5, colsample_bytree =
0.5, nround = 1, objective = "binary:logistic"
)
#-------------Test prediction-----------------
p <- predict(bst, as.matrix(test[,feat]))
if (i == 1) {
pred <- p
}else{
pred <- pred + p
}
}
submit <- pred / (length(events) - 2)
write.csv(
as.data.frame(submit),'pred/submission_20151106_xg_rf.csv',quote = FALSE,row.names = FALSE
)
