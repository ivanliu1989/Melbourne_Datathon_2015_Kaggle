rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$PRED_PROFIT_LOSS_2)
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v[,6])
# Partial AUC:
# print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
# Plot plot(rocobj)
# Performance Selection
perf_new <- auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE)
# rocobj;perf_new
if (perf_new > perf){
perf <- perf_new
print (paste0('lambda: ', d3, ' | nlambda: ', d1, ' | lambda.min.ratio: ', d2))
print(auc(rocobj)); print(perf_new)
}
}
}
}
fit
perf_new
fit <- h2o.deeplearning(y = dependent, x = independent, data = train_df,
classification_stop = -1, activation="RectifierWithDropout",#TanhWithDropout "RectifierWithDropout"
hidden=c(128,128,128), hidden_dropout_ratios = c(0.1,0.1,0.1), input_dropout_ratio = 0.5,
epochs=5, adaptive_rate = T, rho = 0.99, epsilon = 1e-10, # 1e-4
rate_decay=0.8,rate= 0.2,momentum_start = 0.5, momentum_stable=0.99,
nesterov_accelerated_gradient = T, loss='CrossEntropy', l2=3e-6, max_w2=2,
seed=8,variable_importances=F,sparse= F,diagnostics=T,shuffle_training_data=T)# classification=T, autoencoder = F,
fit
val <- validation
pred <- h2o.predict(object = fit, newdata = validation_df)
val <- cbind(val, as.data.frame(pred[,3]))
val$PRED_PROFIT_LOSS <- (val[,ncol(val)] - 0.5) * val$INVEST * 2
pred_fin <- aggregate(PRED_PROFIT_LOSS ~ ACCOUNT_ID, data=val, sum, na.rm=T)
pred_fin$PRED_PROFIT_LOSS_2 <- ifelse(pred_fin$PRED_PROFIT_LOSS > 0, 1, ifelse(pred_fin$PRED_PROFIT_LOSS < 0, 0, 0.5))
pred_fin2 <- aggregate(X1 ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
# print(fit)
# With a roc object:
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$PRED_PROFIT_LOSS_2)
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v[,6])
# Performance Selection
perf_new <- auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE)
rocobj;perf_new
pred
write.csv(pred, file = 'ReadyForBlending/validation/0_deeplearning_1.csv')
write.csv(pred,'ReadyForBlending/validation/0_deeplearning_1.csv',quote = FALSE,row.names = FALSE)
write.csv(pred,'/ReadyForBlending/validation/0_deeplearning_1.csv',quote = FALSE,row.names = FALSE)
as.data.frame(pred)
write.csv(as.data.frame(pred),'/ReadyForBlending/validation/0_deeplearning_1.csv',quote = FALSE,row.names = FALSE)
write.csv(as.data.frame(pred),file='/ReadyForBlending/validation/0_deeplearning_1.csv',quote = FALSE,row.names = FALSE)
write.csv(as.data.frame(pred),file='ReadyForBlending/validation/0_deeplearning_1.csv',quote = FALSE,row.names = FALSE)
fit <-
h2o.deeplearning(
y = dependent, x = independent, data = train_df,
classification_stop = -1, activation =
"RectifierWithDropout",#TanhWithDropout "RectifierWithDropout"
hidden = c(128,128,128), hidden_dropout_ratios = c(0.1,0.1,0.1), input_dropout_ratio = 0.5,
epochs = 5, adaptive_rate = T, rho = 0.99, epsilon = 1e-10, # 1e-4
rate_decay = 0.8, rate = 0.2, momentum_start = 0.5, momentum_stable =
0.99,
nesterov_accelerated_gradient = T, loss =
'CrossEntropy', l2 = 3e-6, max_w2 = 2,
seed = 8,variable_importances =
F,sparse = F,diagnostics = T,shuffle_training_data = T
)
fit
val <- validation
pred <- h2o.predict(object = fit, newdata = validation_df)
val <- cbind(val, as.data.frame(pred[,3]))
val$PRED_PROFIT_LOSS <- (val[,ncol(val)] - 0.5) * val$INVEST * 2
pred_fin <- aggregate(PRED_PROFIT_LOSS ~ ACCOUNT_ID, data=val, sum, na.rm=T)
pred_fin$PRED_PROFIT_LOSS_2 <- ifelse(pred_fin$PRED_PROFIT_LOSS > 0, 1, ifelse(pred_fin$PRED_PROFIT_LOSS < 0, 0, 0.5))
pred_fin2 <- aggregate(X1 ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
# print(fit)
# With a roc object:
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$PRED_PROFIT_LOSS_2)
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v[,6])
# Performance Selection
perf_new <- auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE)
rocobj;perf_new
write.csv(as.data.frame(pred),file='ReadyForBlending/validation/0_deeplearning_2_8026.csv',quote = FALSE,row.names = FALSE)
fit <-
h2o.deeplearning(
y = dependent, x = independent, data = train_df,
classification_stop = -1, activation =
"RectifierWithDropout",#TanhWithDropout "RectifierWithDropout"
hidden = c(128,128,128), hidden_dropout_ratios = c(0.1,0.1,0.1), input_dropout_ratio = 0.5,
epochs = 5, adaptive_rate = T, rho = 0.99, epsilon = 1e-10, # 1e-4
rate_decay = 0.8, rate = 0.2, momentum_start = 0.5, momentum_stable =
0.99,
nesterov_accelerated_gradient = T, loss =
'CrossEntropy', l2 = 3e-6, max_w2 = 2,
seed = 8,variable_importances =
F,sparse = F,diagnostics = T,shuffle_training_data = T
)
#             fit <-
#                 h2o.randomForest(
#                     y = dependent, x = independent, data = train_df, #validation_frame
#                     ntree = 100, depth = 10, mtries =
#                         8, sample.rate = 0.8, nbins = 10, seed = 8
#                 )
#
#             fit <-
#                 h2o.naiveBayes(
#                     y = dependent, x = independent, data = train_df, laplace = 0
#                 )
#
#             fit <-
#                 h2o.glm(
#                     y = dependent, x = independent, data = train_df,
#                     family = 'binomial', link = 'logit',alpha = 0.5, # 1 lasso 0 ridge
#                     lambda = 1e-08, lambda_search = T, nlambda = 8, lambda.min.ratio = 0.1,
#                     strong_rules = T, standardize = T, intercept = T, use_all_factor_levels = F,
#                     epsilon = 1e-4, iter.max = 100, higher_accuracy = T, disable_line_search = F
#                 )
#
##################
### Prediction ###
##################
val <- validation
pred <- h2o.predict(object = fit, newdata = validation_df)
val <- cbind(val, as.data.frame(pred[,3]))
val$PRED_PROFIT_LOSS <- (val[,ncol(val)] - 0.5) * val$INVEST * 2
pred_fin <- aggregate(PRED_PROFIT_LOSS ~ ACCOUNT_ID, data=val, sum, na.rm=T)
pred_fin$PRED_PROFIT_LOSS_2 <- ifelse(pred_fin$PRED_PROFIT_LOSS > 0, 1, ifelse(pred_fin$PRED_PROFIT_LOSS < 0, 0, 0.5))
pred_fin2 <- aggregate(X1 ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
# print(fit)
# With a roc object:
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$PRED_PROFIT_LOSS_2)
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v[,6])
# Performance Selection
perf_new <- auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE)
rocobj;perf_new
write.csv(as.data.frame(pred),file='ReadyForBlending/validation/0_deeplearning_3_8239.csv',quote = FALSE,row.names = FALSE)
fit
fit <-
h2o.deeplearning(
y = dependent, x = independent, data = train_df,
classification_stop = -1, activation =
"RectifierWithDropout",#TanhWithDropout "RectifierWithDropout"
hidden = c(128,128,128), hidden_dropout_ratios = c(0.1,0.1,0.1), input_dropout_ratio = 0.5,
epochs = 5, adaptive_rate = T, rho = 0.99, epsilon = 1e-10, # 1e-4
rate_decay = 0.8, rate = 0.2, momentum_start = 0.5, momentum_stable =
0.99,
nesterov_accelerated_gradient = T, loss =
'CrossEntropy', l2 = 3e-6, max_w2 = 2,
seed = 8,variable_importances =
F,sparse = F,diagnostics = T,shuffle_training_data = T
)
#             fit <-
#                 h2o.randomForest(
#                     y = dependent, x = independent, data = train_df, #validation_frame
#                     ntree = 100, depth = 10, mtries =
#                         8, sample.rate = 0.8, nbins = 10, seed = 8
#                 )
#
#             fit <-
#                 h2o.naiveBayes(
#                     y = dependent, x = independent, data = train_df, laplace = 0
#                 )
#
#             fit <-
#                 h2o.glm(
#                     y = dependent, x = independent, data = train_df,
#                     family = 'binomial', link = 'logit',alpha = 0.5, # 1 lasso 0 ridge
#                     lambda = 1e-08, lambda_search = T, nlambda = 8, lambda.min.ratio = 0.1,
#                     strong_rules = T, standardize = T, intercept = T, use_all_factor_levels = F,
#                     epsilon = 1e-4, iter.max = 100, higher_accuracy = T, disable_line_search = F
#                 )
#
##################
### Prediction ###
##################
val <- validation
pred <- h2o.predict(object = fit, newdata = validation_df)
val <- cbind(val, as.data.frame(pred[,3]))
val$PRED_PROFIT_LOSS <- (val[,ncol(val)] - 0.5) * val$INVEST * 2
pred_fin <- aggregate(PRED_PROFIT_LOSS ~ ACCOUNT_ID, data=val, sum, na.rm=T)
pred_fin$PRED_PROFIT_LOSS_2 <- ifelse(pred_fin$PRED_PROFIT_LOSS > 0, 1, ifelse(pred_fin$PRED_PROFIT_LOSS < 0, 0, 0.5))
pred_fin2 <- aggregate(X1 ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
# print(fit)
# With a roc object:
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$PRED_PROFIT_LOSS_2)
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v[,6])
# Performance Selection
perf_new <- auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE)
rocobj;perf_new
write.csv(as.data.frame(pred),file='ReadyForBlending/validation/0_deeplearning_4_8201.csv',quote = FALSE,row.names = FALSE)
fit <-
h2o.deeplearning(
y = dependent, x = independent, data = train_df,
classification_stop = -1, activation =
"RectifierWithDropout",#TanhWithDropout "RectifierWithDropout"
hidden = c(128,128,128), hidden_dropout_ratios = c(0.1,0.1,0.1), input_dropout_ratio = 0.5,
epochs = 5, adaptive_rate = T, rho = 0.99, epsilon = 1e-10, # 1e-4
rate_decay = 0.8, rate = 0.2, momentum_start = 0.5, momentum_stable =
0.99,
nesterov_accelerated_gradient = T, loss =
'CrossEntropy', l2 = 3e-6, max_w2 = 2,
seed = 8,variable_importances =
F,sparse = F,diagnostics = T,shuffle_training_data = T
)
#             fit <-
#                 h2o.randomForest(
#                     y = dependent, x = independent, data = train_df, #validation_frame
#                     ntree = 100, depth = 10, mtries =
#                         8, sample.rate = 0.8, nbins = 10, seed = 8
#                 )
#
#             fit <-
#                 h2o.naiveBayes(
#                     y = dependent, x = independent, data = train_df, laplace = 0
#                 )
#
#             fit <-
#                 h2o.glm(
#                     y = dependent, x = independent, data = train_df,
#                     family = 'binomial', link = 'logit',alpha = 0.5, # 1 lasso 0 ridge
#                     lambda = 1e-08, lambda_search = T, nlambda = 8, lambda.min.ratio = 0.1,
#                     strong_rules = T, standardize = T, intercept = T, use_all_factor_levels = F,
#                     epsilon = 1e-4, iter.max = 100, higher_accuracy = T, disable_line_search = F
#                 )
#
##################
### Prediction ###
##################
val <- validation
pred <- h2o.predict(object = fit, newdata = validation_df)
val <- cbind(val, as.data.frame(pred[,3]))
val$PRED_PROFIT_LOSS <- (val[,ncol(val)] - 0.5) * val$INVEST * 2
pred_fin <- aggregate(PRED_PROFIT_LOSS ~ ACCOUNT_ID, data=val, sum, na.rm=T)
pred_fin$PRED_PROFIT_LOSS_2 <- ifelse(pred_fin$PRED_PROFIT_LOSS > 0, 1, ifelse(pred_fin$PRED_PROFIT_LOSS < 0, 0, 0.5))
pred_fin2 <- aggregate(X1 ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
print(fit)
# With a roc object:
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$PRED_PROFIT_LOSS_2)
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v[,6])
# Performance Selection
perf_new <- auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE)
rocobj;perf_new
write.csv(as.data.frame(pred),file='ReadyForBlending/validation/0_deeplearning_5_8261.csv',quote = FALSE,row.names = FALSE)
plot(perf_new)
plot(rocobj)
file.names <- files('ReadyForBlending/validation/')
file.names <- file.path('ReadyForBlending/validation/')
file.names
file.names <- list.files('ReadyForBlending/validation/')
file.names
pred <- c()
read.csv(paste0('ReadyForBlending/validation/', file.names[1]))
exists(pre)
exists(pred)
is.na(pred)
file.names
for(file in 1:length(file.names)){
p <- read.csv(paste0('ReadyForBlending/validation/', file.names[file]))
if(file=1){
pred <- p
}else{
pred <- p + pred
}
}
for(file in 1:length(file.names)){
p <- read.csv(paste0('ReadyForBlending/validation/', file.names[file]))
if(file==1){
pred <- p
}else{
pred <- p + pred
}
}
head(pred)
for(file in 1:length(file.names)){
p <- read.csv(paste0('ReadyForBlending/validation/', file.names[file]))
if(file==1){
pred <- p
}else{
pred <- p + pred
}
if(file==length(file.names)) pred <- pred/file
}
head(pred)
load('data/9_train_validation_test_TREE_1.RData');ls()
val <- validation
val <- cbind(val, pred[,3])
val$PRED_PROFIT_LOSS <- (val[,ncol(val)] - 0.5) * val$INVEST * 2
pred_fin <- aggregate(PRED_PROFIT_LOSS ~ ACCOUNT_ID, data=val, sum, na.rm=T)
pred_fin$PRED_PROFIT_LOSS_2 <- ifelse(pred_fin$PRED_PROFIT_LOSS > 0, 1, ifelse(pred_fin$PRED_PROFIT_LOSS < 0, 0, 0.5))
pred_fin2 <- aggregate(X1 ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
# With a roc object:
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$PRED_PROFIT_LOSS_2)
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v[,6])
perf_new <- auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE)
rocobj;perf_new
pred[,3]
head(pred)
val <- cbind(val, pred[,3])
val$PRED_PROFIT_LOSS <- (val[,ncol(val)] - 0.5) * val$INVEST * 2
pred_fin <- aggregate(PRED_PROFIT_LOSS ~ ACCOUNT_ID, data=val, sum, na.rm=T)
pred_fin$PRED_PROFIT_LOSS_2 <- ifelse(pred_fin$PRED_PROFIT_LOSS > 0, 1, ifelse(pred_fin$PRED_PROFIT_LOSS < 0, 0, 0.5))
pred_fin2 <- aggregate(X1 ~ ACCOUNT_ID, data=val, mean, na.rm=F)
head(val)
val <- cbind(val, pred$X1)
head(val)
val <- validation
X1 <- pred[,3]
val <- cbind(val, X1)
val$PRED_PROFIT_LOSS <- (val[,ncol(val)] - 0.5) * val$INVEST * 2
pred_fin <- aggregate(PRED_PROFIT_LOSS ~ ACCOUNT_ID, data=val, sum, na.rm=T)
pred_fin$PRED_PROFIT_LOSS_2 <- ifelse(pred_fin$PRED_PROFIT_LOSS > 0, 1, ifelse(pred_fin$PRED_PROFIT_LOSS < 0, 0, 0.5))
pred_fin2 <- aggregate(X1 ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
# With a roc object:
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$PRED_PROFIT_LOSS_2)
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v[,6])
perf_new <- auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE)
rocobj;perf_new
plot(rocobj)
setwd('/Users/ivanliu/Google Drive/Melbourne Datathon/Melbourne_Datathon_2015_Kaggle')
setwd('C:\\Users\\iliu2\\Documents\\datathon\\Melbourne_Datathon_2015_Kaggle')
rm(list=ls()); gc()
library(pROC)
load('data/9_train_validation_test_TREE_1.RData');ls()
# load('data/9_train_validation_test_ONEHOT_1.RData');ls()
file.names <- list.files('ReadyForBlending/validation/')
for(file in 1:length(file.names)){
p <- read.csv(paste0('ReadyForBlending/validation/', file.names[file]))
if(file==1){
pred <- p
}else{
pred <- p + pred
}
if(file==length(file.names)) pred <- pred/file
}
head(pred)
##################
### Prediction ###
##################
val <- validation
X1 <- pred[,3]
val <- cbind(val, X1)
val$PRED_PROFIT_LOSS <- (val[,ncol(val)] - 0.5) * val$INVEST * 2
pred_fin <- aggregate(PRED_PROFIT_LOSS ~ ACCOUNT_ID, data=val, sum, na.rm=T)
pred_fin$PRED_PROFIT_LOSS_2 <- ifelse(pred_fin$PRED_PROFIT_LOSS > 0, 1, ifelse(pred_fin$PRED_PROFIT_LOSS < 0, 0, 0.5))
pred_fin2 <- aggregate(X1 ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
# With a roc object:
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$PRED_PROFIT_LOSS_2)
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v[,6])
perf_new <- auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE)
rocobj;perf_new
plot(rocobj)
setwd('/Users/ivanliu/Google Drive/Melbourne Datathon/Melbourne_Datathon_2015_Kaggle')
setwd('C:\\Users\\iliu2\\Documents\\datathon\\Melbourne_Datathon_2015_Kaggle')
rm(list=ls()); gc()
library(pROC)
load('data/9_train_validation_test_TREE_1.RData');ls()
# load('data/9_train_validation_test_ONEHOT_1.RData');ls()
file.names <- list.files('ReadyForBlending/validation/')
for(file in 1:length(file.names)){
p <- read.csv(paste0('ReadyForBlending/validation/', file.names[file]))
if(file==1){
pred <- p
}else{
pred <- p + pred
}
if(file==length(file.names)) pred <- pred/file
}
head(pred)
##################
### Prediction ###
##################
val <- validation
X1 <- pred[,3]
val <- cbind(val, X1)
val$PRED_PROFIT_LOSS <- (val[,ncol(val)] - 0.5) * val$INVEST * 2
pred_fin <- aggregate(PRED_PROFIT_LOSS ~ ACCOUNT_ID, data=val, sum, na.rm=T)
pred_fin$PRED_PROFIT_LOSS_2 <- ifelse(pred_fin$PRED_PROFIT_LOSS > 0, 1, ifelse(pred_fin$PRED_PROFIT_LOSS < 0, 0, 0.5))
pred_fin2 <- aggregate(X1 ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
# With a roc object:
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$PRED_PROFIT_LOSS_2)
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v[,6])
perf_new <- auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE)
rocobj;perf_new
plot(rocobj)
perf_new
as.numeric(perf_new)
fit <-
h2o.deeplearning(
y = dependent, x = independent, data = train_df,
classification_stop = -1, activation =
"TanhWithDropout",#TanhWithDropout "RectifierWithDropout"
hidden = c(128,128,128), hidden_dropout_ratios = c(0.1,0.1,0.1), input_dropout_ratio = 0.5,
epochs = 5, adaptive_rate = T, rho = 0.99, epsilon = 1e-10, # 1e-4
rate_decay = 0.8, rate = 0.2, momentum_start = 0.5, momentum_stable =
0.99,
nesterov_accelerated_gradient = T, loss =
'CrossEntropy', l2 = 3e-6, max_w2 = 2,
seed = 8,variable_importances =
F,sparse = F,diagnostics = T,shuffle_training_data = T
)
#             fit <-
#                 h2o.randomForest(
#                     y = dependent, x = independent, data = train_df, #validation_frame
#                     ntree = 100, depth = 10, mtries =
#                         8, sample.rate = 0.8, nbins = 10, seed = 8
#                 )
#
#             fit <-
#                 h2o.naiveBayes(
#                     y = dependent, x = independent, data = train_df, laplace = 0
#                 )
#
#             fit <-
#                 h2o.glm(
#                     y = dependent, x = independent, data = train_df,
#                     family = 'binomial', link = 'logit',alpha = 0.5, # 1 lasso 0 ridge
#                     lambda = 1e-08, lambda_search = T, nlambda = 8, lambda.min.ratio = 0.1,
#                     strong_rules = T, standardize = T, intercept = T, use_all_factor_levels = F,
#                     epsilon = 1e-4, iter.max = 100, higher_accuracy = T, disable_line_search = F
#                 )
#
##################
### Prediction ###
##################
val <- validation
pred <- h2o.predict(object = fit, newdata = validation_df)
val <- cbind(val, as.data.frame(pred[,3]))
val$PRED_PROFIT_LOSS <- (val[,ncol(val)] - 0.5) * val$INVEST * 2
pred_fin <- aggregate(PRED_PROFIT_LOSS ~ ACCOUNT_ID, data=val, sum, na.rm=T)
pred_fin$PRED_PROFIT_LOSS_2 <- ifelse(pred_fin$PRED_PROFIT_LOSS > 0, 1, ifelse(pred_fin$PRED_PROFIT_LOSS < 0, 0, 0.5))
pred_fin2 <- aggregate(X1 ~ ACCOUNT_ID, data=val, mean, na.rm=F)
### Validation
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, ifelse(val_fin$flag_regr < 0, 0, 0.5))
#########################
### Model Performance ###
#########################
v <- merge(val_fin,pred_fin,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
v <- merge(v,pred_fin2,all.x = TRUE,all.y = FALSE, by = 'ACCOUNT_ID')
# With a roc object:
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v$PRED_PROFIT_LOSS_2)
rocobj <- roc(v$PRED_PROFIT_LOSS_3, v[,6])
# Performance Selection
perf_new <- auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE)
rocobj;perf_new
