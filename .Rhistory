writeLines("Successfilly opened connection to db")
return(c)
}else{
writeLines(paste0("Error opening connection: ", as.character(c)))
}
}
}
# rdp.csgplatform.com:5685
cn <- connect(host='localhost', db='comtrade_source', user='sa', pass='Servian1', platform="mac")
ch1 <- odbcConnect(dsn="sqlserver01", uid="sa", pwd="Servian1")
require(Rserve)
Rserve()
Rserve()
install.packages(c("boot", "gtools", "manipulate"))
head(train)
rm(list = ls()); gc()
require(data.table);require(caret);require(doMC);require(ROCR)
registerDoMC(core=3)
load('data/new/cv_data_log_extend.RData')
install.packages("manipulate")
data("iris")
# this is a little tweak so that things line up nicely later on
iris$Species <- factor(iris$Species,
levels = c("versicolor","virginica","setosa"))
head(iris)
ound(cor(iris[,1:4]), 2)
round(cor(iris[,1:4]), 2)
pc <- princomp(iris[,1:4], cor=TRUE, scores=TRUE)
pc
summary(pc)
plot(pc,type="lines")
biplot(pc)
library(rgl)
plot3d(pc$scores[,1:3], col=iris$Species)
plot3d(pc$scores[,1:3], col=iris$Species)
plot3d(pc$scores[,1:3])#, col=iris$Species)
text3d(pc$scores[,1:3],texts=rownames(iris))
text3d(pc$loadings[,1:3], texts=rownames(pc$loadings), col="red")
coords <- NULL
for (i in 1:nrow(pc$loadings)) {
coords <- rbind(coords, rbind(c(0,0,0),pc$loadings[i,1:3]))
}
for (i in 1:nrow(pc$loadings)) {
coords <- rbind(coords, rbind(c(0,0,0),pc$loadings[i,1:3]))
}
lines3d(coords, col="red", lwd=4)
set.seed(42)
cl <- kmeans(iris[,1:4],3)
iris$cluster <- as.factor(cl$cluster)
plot3d(pc$scores[,1:3], col=iris$cluster, main="k-means clusters")
plot3d(pc$scores[,1:3], col=iris$Species, main="actual species")
with(iris, table(cluster, Species))
data("iris")
# this is a little tweak so that things line up nicely later on
iris$Species <- factor(iris$Species,
levels = c("versicolor","virginica","setosa"))
head(iris)
round(cor(iris[,1:4]), 2)
pc <- princomp(iris[,1:4], cor=TRUE, scores=TRUE)
summary(pc)
plot(pc,type="lines")
biplot(pc)
library(rgl)
plot3d(pc$scores[,1:3], col=iris$Species)
text3d(pc$scores[,1:3],texts=rownames(iris))
text3d(pc$loadings[,1:3], texts=rownames(pc$loadings), col="red")
coords <- NULL
for (i in 1:nrow(pc$loadings)) {
coords <- rbind(coords, rbind(c(0,0,0),pc$loadings[i,1:3]))
}
lines3d(coords, col="red", lwd=4)
set.seed(42)
cl <- kmeans(iris[,1:4],3)
iris$cluster <- as.factor(cl$cluster)
plot3d(pc$scores[,1:3], col=iris$cluster, main="k-means clusters")
setwd('/Users/ivanliu/Google Drive/Melbourne Datathon/Melbourne_Datathon_2015_Kaggle')
rm(list=ls()); gc(); library(caret)
# load('data/Ivan_train_test_20151116.RData');ls()
load('data/v3/Ivan_train_test_20151115.RData');
head(train)
setwd('/Users/ivanliu/Google Drive/Melbourne Datathon/Melbourne_Datathon_2015_Kaggle')
rm(list=ls()); gc(); library(caret)
# source('Rscripts/12_log_transformation.R')
load('data/1_complete_data.RData');
load('data/2_test.RData');ls()
load('data/v1/1_complete_data.RData');
load('data/v1/2_test.RData');ls()
head(total)
test$flag_regr <- 0
test$flag_class <- 'M'
# apply(all,2, function(x) mean(is.na(x)))
all <- rbind(total, test); str(all)
all$COUNTRY_OF_RESIDENCE_NAME <- NULL
apply(all,2, function(x) mean(is.na(x)))
all$INVEST <- all$TRANSACTION_COUNT_INPLAY * all$AVG_BET_SIZE_INPLAY + all$TRANSACTION_COUNT_OUTPLAY * all$AVG_BET_SIZE_OUTPLAY
setwd('/Users/ivanliu/Google Drive/Melbourne Datathon/Melbourne_Datathon_2015_Kaggle')
rm(list=ls()); gc(); library(caret)
# source('Rscripts/12_log_transformation.R')
load('data/v1/1_complete_data.RData');
load('data/v1/2_test.RData');ls()
#################################
# 0. Test feature complete ######
#################################
test$flag_regr <- 0
test$flag_class <- 'M'
head(test)
apply(test,2, function(x) mean(is.na(x)))
apply(test,2, function(x) mean(is.na(x)))==0
all <- test[,apply(test,2, function(x) mean(is.na(x)))==0]
head(all)
all <- test[is.na(test$AVG_PLACED_TAKEN_TIME_INPLAY),apply(test,2, function(x) mean(is.na(x)))==0]
dim(all)
head(all)
all$INVEST <- all$TRANSACTION_COUNT_INPLAY * all$AVG_BET_SIZE_INPLAY + all$TRANSACTION_COUNT_OUTPLAY * all$AVG_BET_SIZE_OUTPLAY
head(all)
dim(all)
test_n <- all[,c(1:34, 37, 35:36)]
head(test_n)
save(test_n, file='data/9_test_n_20151122.RData')
setwd('/Users/ivanliu/Google Drive/Melbourne Datathon/Melbourne_Datathon_2015_Kaggle')
rm(list=ls()); gc()
library(xgboost);library(pROC);require(randomForest);library(caret);
load('data/9_train_validation_test_20151122.RData');ls()
load('data/9_test_n_20151122.RData');ls()
train_n <- train[,colnames(test_n)]
dim(train_n)
total_n <- total[,colnames(test_n)]
dim(total_n)
save(test,total,train,test_n,total_n, file = 'data/9_train_validation_test_20151122.RData')
setwd('/Users/ivanliu/Google Drive/Melbourne Datathon/Melbourne_Datathon_2015_Kaggle')
rm(list=ls()); gc()
library(xgboost);library(pROC);require(randomForest);library(caret);
load('data/9_train_validation_test_20151122.RData');ls()
# load('data/v5/Ivan_Train_Test_Scale_Center_20151123.RData');
options(scipen=999);set.seed(19890624)
inTraining <- createDataPartition(total$flag_class, p = .3, list = FALSE)
test <- test_n#total[train$EVENT_ID %in% c(101183757,101183885,101184013),]
train <- total_n#[-inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
validation <- total_n[inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
train$flag_class <- ifelse(train$flag_class == 'Y', 1, 0)
test$flag_class <- ifelse(test$flag_class == 'Y', 1, 0)
validation$flag_class <- ifelse(validation$flag_class == 'Y', 1, 0)
feat <- colnames(train)[c(3:(ncol(train)-2))] # train
feat
dtrain <- xgb.DMatrix(as.matrix(train[,feat]), label = train$flag_class)
dtest <- xgb.DMatrix(as.matrix(test[,feat]),label = test$flag_class)
dvalid <- xgb.DMatrix(as.matrix(validation[,feat]),label = validation$flag_class)
watchlist <- list(eval = dvalid, train = dtrain)
bst <-
xgb.train(
data = dtrain, max.depth = 6, eta = 0.02, nround = 1500, maximize = F, min_child_weight = 2, colsample_bytree = 1, #early.stop.round = 100,
nthread = 4, objective = "binary:logistic", verbose = 1, print.every.n = 10, metrics = 'auc', #num_parallel_tree = 1, gamma = 0.1,
watchlist = watchlist
)
p_gbm = predict(bst,dvalid)
val <- validation
val$Y <- p_gbm
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, sum, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, 0)
### Model Performance ###
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin[,2]);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin2[,2]);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
prediction <- as.factor(ifelse(pred_fin[,2] >=0.5, 1, 0))
confusionMatrix(as.factor(val_fin$PRED_PROFIT_LOSS_3), prediction)
inTraining <- createDataPartition(total$flag_class, p = .3, list = FALSE)
test <- test_n#total[train$EVENT_ID %in% c(101183757,101183885,101184013),]
train <- total_n[-inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
validation <- total_n[inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
train$flag_class <- ifelse(train$flag_class == 'Y', 1, 0)
test$flag_class <- ifelse(test$flag_class == 'Y', 1, 0)
validation$flag_class <- ifelse(validation$flag_class == 'Y', 1, 0)
feat <- colnames(train)[c(3:(ncol(train)-2))] # train
dtrain <- xgb.DMatrix(as.matrix(train[,feat]), label = train$flag_class)
dtest <- xgb.DMatrix(as.matrix(test[,feat]),label = test$flag_class)
dvalid <- xgb.DMatrix(as.matrix(validation[,feat]),label = validation$flag_class)
watchlist <- list(eval = dvalid, train = dtrain)
bst <-
xgb.train(
data = dtrain, max.depth = 6, eta = 0.02, nround = 1500, maximize = F, min_child_weight = 2, colsample_bytree = 1, #early.stop.round = 100,
nthread = 4, objective = "binary:logistic", verbose = 1, print.every.n = 10, metrics = 'auc', #num_parallel_tree = 1, gamma = 0.1,
watchlist = watchlist
)
p_gbm = predict(bst,dvalid)
val <- validation
# p <- ifelse(p_gbm>0.5, 1, 0)
val$Y <- p_gbm
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, sum, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, 0)
### Model Performance ###
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin[,2]);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin2[,2]);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
prediction <- as.factor(ifelse(pred_fin[,2] >=0.5, 1, 0))
confusionMatrix(as.factor(val_fin$PRED_PROFIT_LOSS_3), prediction)
bst <-
xgb.train(
data = dtrain, max.depth = 5, eta = 0.15, nround = 500, maximize = F, min_child_weight = 2, colsample_bytree = 1, #early.stop.round = 100,
nthread = 4, objective = "binary:logistic", verbose = 1, print.every.n = 10, metrics = 'auc', #num_parallel_tree = 1, gamma = 0.1,
watchlist = watchlist
)
p_gbm = predict(bst,dvalid)
val <- validation
# p <- ifelse(p_gbm>0.5, 1, 0)
val$Y <- p_gbm
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, sum, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, 0)
### Model Performance ###
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin[,2]);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin2[,2]);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
prediction <- as.factor(ifelse(pred_fin[,2] >=0.5, 1, 0))
confusionMatrix(as.factor(val_fin$PRED_PROFIT_LOSS_3), prediction)
p_gbm = predict(bst,dvalid)
val <- validation
val$Y <- p_gbm
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, sum, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, 0)
### Model Performance ###
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin[,2]);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin2[,2]);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
prediction <- as.factor(ifelse(pred_fin[,2] >=0.5, 1, 0))
confusionMatrix(as.factor(val_fin$PRED_PROFIT_LOSS_3), prediction)
bst <-
xgb.train(
data = dtrain, max.depth = 4, eta = 0.15, nround = 500, maximize = F, min_child_weight = 4, colsample_bytree = 1, #early.stop.round = 100,
nthread = 4, objective = "binary:logistic", verbose = 1, print.every.n = 10, metrics = 'auc', #num_parallel_tree = 1, gamma = 0.1,
watchlist = watchlist
)
# p_gbm = predict(bst,dtest)
p_gbm = predict(bst,dvalid)
val <- validation
# p <- ifelse(p_gbm>0.5, 1, 0)
val$Y <- p_gbm
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, sum, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, 0)
### Model Performance ###
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin[,2]);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin2[,2]);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
prediction <- as.factor(ifelse(pred_fin[,2] >=0.5, 1, 0))
confusionMatrix(as.factor(val_fin$PRED_PROFIT_LOSS_3), prediction)
bst <-
xgb.train(
data = dtrain, max.depth = 4, eta = 0.15, nround = 500, maximize = F, min_child_weight = 1, colsample_bytree = 1, #early.stop.round = 100,
nthread = 4, objective = "binary:logistic", verbose = 1, print.every.n = 10, metrics = 'auc', #num_parallel_tree = 1, gamma = 0.1,
watchlist = watchlist
)
# p_gbm = predict(bst,dtest)
p_gbm = predict(bst,dvalid)
val <- validation
# p <- ifelse(p_gbm>0.5, 1, 0)
val$Y <- p_gbm
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, sum, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, 0)
### Model Performance ###
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin[,2]);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin2[,2]);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
prediction <- as.factor(ifelse(pred_fin[,2] >=0.5, 1, 0))
confusionMatrix(as.factor(val_fin$PRED_PROFIT_LOSS_3), prediction)
bst <-
xgb.train(
data = dtrain, max.depth = 4, eta = 0.25, nround = 500, maximize = F, min_child_weight = 1, colsample_bytree = 1, #early.stop.round = 100,
nthread = 4, objective = "binary:logistic", verbose = 1, print.every.n = 10, metrics = 'auc', #num_parallel_tree = 1, gamma = 0.1,
watchlist = watchlist
)
# p_gbm = predict(bst,dtest)
p_gbm = predict(bst,dvalid)
bst <-
xgb.train( # max.depth = 6, eta = 0.02, nround = 1200,
data = dtrain, max.depth = 5, eta = 0.1, nround = 800, maximize = F, min_child_weight = 1, colsample_bytree = 1, #early.stop.round = 100,
nthread = 4, objective = "binary:logistic", verbose = 1, print.every.n = 10, metrics = 'auc', #num_parallel_tree = 1, gamma = 0.1,
watchlist = watchlist
)
# p_gbm = predict(bst,dtest)
p_gbm = predict(bst,dvalid)
bst <-
xgb.train( # max.depth = 6, eta = 0.02, nround = 1200,
data = dtrain, max.depth = 5, eta = 0.15, nround = 500, maximize = F, min_child_weight = 1, colsample_bytree = 1, #early.stop.round = 100,
nthread = 4, objective = "binary:logistic", verbose = 1, print.every.n = 10, metrics = 'auc', #num_parallel_tree = 1, gamma = 0.1,
watchlist = watchlist
)
bst <-
xgb.train( # max.depth = 6, eta = 0.02, nround = 1200,
data = dtrain, max.depth = 3, eta = 0.15, nround = 500, maximize = F, min_child_weight = 1, colsample_bytree = 1, #early.stop.round = 100,
nthread = 4, objective = "binary:logistic", verbose = 1, print.every.n = 10, metrics = 'auc', #num_parallel_tree = 1, gamma = 0.1,
watchlist = watchlist
)
# p_gbm = predict(bst,dtest)
p_gbm = predict(bst,dvalid)
bst <-
xgb.train( # max.depth = 6, eta = 0.02, nround = 1200,
data = dtrain, max.depth = 4, eta = 0.15, nround = 500, maximize = F, min_child_weight = 1, colsample_bytree = 1, #early.stop.round = 100,
nthread = 4, objective = "binary:logistic", verbose = 1, print.every.n = 10, metrics = 'auc', #num_parallel_tree = 1, gamma = 0.1,
watchlist = watchlist
)
# p_gbm = predict(bst,dtest)
p_gbm = predict(bst,dvalid)
test <- test_n#total[train$EVENT_ID %in% c(101183757,101183885,101184013),]
train <- total_n#[-inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
inTraining <- createDataPartition(total$flag_class, p = .3, list = FALSE)
test <- test_n#total[train$EVENT_ID %in% c(101183757,101183885,101184013),]
train <- total_n#[-inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
validation <- total_n[inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
train$flag_class <- ifelse(train$flag_class == 'Y', 1, 0)
test$flag_class <- ifelse(test$flag_class == 'Y', 1, 0)
validation$flag_class <- ifelse(validation$flag_class == 'Y', 1, 0)
feat <- colnames(train)[c(3:(ncol(train)-2))] # train
dtrain <- xgb.DMatrix(as.matrix(train[,feat]), label = train$flag_class)
dtest <- xgb.DMatrix(as.matrix(test[,feat]),label = test$flag_class)
dvalid <- xgb.DMatrix(as.matrix(validation[,feat]),label = validation$flag_class)
watchlist <- list(eval = dvalid, train = dtrain)
bst <-
xgb.train( # max.depth = 6, eta = 0.02, nround = 1200,
data = dtrain, max.depth = 4, eta = 0.15, nround = 500, maximize = F, min_child_weight = 1, colsample_bytree = 1, #early.stop.round = 100,
nthread = 4, objective = "binary:logistic", verbose = 1, print.every.n = 10, metrics = 'auc', #num_parallel_tree = 1, gamma = 0.1,
watchlist = watchlist
)
p_glm = predict(bst,dtest)
dim(p_glm)
head(p_glm)
p_gbm = predict(bst,dtest)
write.csv(p_gbm, paste0('ReadyForBlending/submission/test_n/xgboost/submission_xgboost_gbm_20151128_', i,'.csv'))
write.csv(p_gbm, paste0('ReadyForBlending/submission/test_n/xgboost/submission_xgboost_gbm_20151128_test_n.csv'))
write.csv(p_gbm, paste0('ReadyForBlending/submission/test_n/xgboost_gbm/submission_xgboost_gbm_20151128_test_n.csv'))
p_gbm
inTraining <- createDataPartition(total$flag_class, p = .3, list = FALSE)
test <- test_n#total[train$EVENT_ID %in% c(101183757,101183885,101184013),]
train <- total_n[-inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
validation <- total_n[inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
train$flag_class <- ifelse(train$flag_class == 'Y', 1, 0)
test$flag_class <- ifelse(test$flag_class == 'Y', 1, 0)
validation$flag_class <- ifelse(validation$flag_class == 'Y', 1, 0)
feat <- colnames(train)[c(3:(ncol(train)-2))] # train
dtrain <- xgb.DMatrix(as.matrix(train[,feat]), label = train$flag_class)
dtest <- xgb.DMatrix(as.matrix(test[,feat]),label = test$flag_class)
dvalid <- xgb.DMatrix(as.matrix(validation[,feat]),label = validation$flag_class)
watchlist <- list(eval = dvalid, train = dtrain)
bst <- xgb.train(
data = dtrain, nround = 350, watchlist = watchlist, objective = "binary:logistic", booster = "gblinear", eta = 0.3,
nthread = 4, alpha = 1e-3, lambda = 1e-6, print.every.n = 10
)
p_glm = predict(bst,dvalid)
val <- validation
val$Y <- p_glm
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, sum, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, 0)
### Model Performance ###
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin[,2]);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin2[,2]);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
prediction <- as.factor(ifelse(pred_fin[,2] >=0.5, 1, 0))
confusionMatrix(as.factor(val_fin$PRED_PROFIT_LOSS_3), prediction)
bst <- xgb.train(
data = dtrain, nround = 1350, watchlist = watchlist, objective = "binary:logistic", booster = "gblinear", eta = 0.13,
nthread = 4, alpha = 1e-3, lambda = 1e-6, print.every.n = 10
)
# p_glm = predict(bst,dtest)
p_glm = predict(bst,dvalid)
val <- validation
# p <- ifelse(p_gbm>0.5, 1, 0)
val$Y <- p_glm
tot_invest <- aggregate(INVEST ~ ACCOUNT_ID,data=val, sum, na.rm=T); names(tot_invest) <- c('ACCOUNT_ID', 'TOT_INVEST')
val <- merge(val, tot_invest, all.x = TRUE, all.y = FALSE, by = c('ACCOUNT_ID'))
val$INVEST_PERCENT <- val$INVEST/val$TOT_INVEST * val$Y
pred_fin <- aggregate(INVEST_PERCENT ~ ACCOUNT_ID, data=val, sum, na.rm=F)
pred_fin2 <- aggregate(Y ~ ACCOUNT_ID, data=val, mean, na.rm=F)
val_fin <- aggregate(flag_regr ~ ACCOUNT_ID, data=val, sum, na.rm=F)
val_fin$PRED_PROFIT_LOSS_3 <- ifelse(val_fin$flag_regr > 0, 1, 0)
### Model Performance ###
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin[,2]);print(auc(rocobj)) # Invest * Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
rocobj <- roc(val_fin$PRED_PROFIT_LOSS_3, pred_fin2[,2]);print(auc(rocobj)) # Average Possibility
print(auc(rocobj, partial.auc=c(1, .8), partial.auc.focus="se", partial.auc.correct=TRUE))
prediction <- as.factor(ifelse(pred_fin[,2] >=0.5, 1, 0))
confusionMatrix(as.factor(val_fin$PRED_PROFIT_LOSS_3), prediction)
bst <- xgb.train(
data = dtrain, nround = 1350, watchlist = watchlist, objective = "binary:logistic", booster = "gblinear", eta = 0.13,
nthread = 4, alpha = 1e-3, lambda = 1e-3, print.every.n = 10
)
# p_glm = predict(bst,dtest)
p_glm = predict(bst,dvalid)
bst <- xgb.train(
data = dtrain, nround = 1350, watchlist = watchlist, objective = "binary:logistic", booster = "gblinear", eta = 0.2,
nthread = 4, alpha = 1e-3, lambda = 1e-3, print.every.n = 10
)
bst <- xgb.train(
data = dtrain, nround = 1350, watchlist = watchlist, objective = "binary:logistic", booster = "gblinear", eta = 0.1,
nthread = 4, alpha = 1e-3, lambda = 1e-3, print.every.n = 10
)
# p_glm = predict(bst,dtest)
p_glm = predict(bst,dvalid)
bst <- xgb.train(
data = dtrain, nround = 1200, watchlist = watchlist, objective = "binary:logistic", booster = "gblinear", eta = 0.15,
nthread = 4, alpha = 1e-3, lambda = 1e-3, print.every.n = 10
)
# p_glm = predict(bst,dtest)
p_glm = predict(bst,dvalid)
inTraining <- createDataPartition(total$flag_class, p = .3, list = FALSE)
test <- test_n#total[train$EVENT_ID %in% c(101183757,101183885,101184013),]
train <- total_n#[-inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
validation <- total_n[inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
train$flag_class <- ifelse(train$flag_class == 'Y', 1, 0)
test$flag_class <- ifelse(test$flag_class == 'Y', 1, 0)
validation$flag_class <- ifelse(validation$flag_class == 'Y', 1, 0)
feat <- colnames(train)[c(3:(ncol(train)-2))] # train
dtrain <- xgb.DMatrix(as.matrix(train[,feat]), label = train$flag_class)
dtest <- xgb.DMatrix(as.matrix(test[,feat]),label = test$flag_class)
dvalid <- xgb.DMatrix(as.matrix(validation[,feat]),label = validation$flag_class)
watchlist <- list(eval = dvalid, train = dtrain)
# 3. generalized linear model
bst <- xgb.train(
data = dtrain, nround = 1200, watchlist = watchlist, objective = "binary:logistic", booster = "gblinear", eta = 0.13,
nthread = 4, alpha = 1e-3, lambda = 1e-3, print.every.n = 10
)
p_glm = predict(bst,dtest)
p_glm = predict(bst,dtest)
write.csv(p_glm, paste0('ReadyForBlending/submission/test_n/xgboost_glm/submission_xgboost_glm_20151128_test_n.csv'))
inTraining <- createDataPartition(total$flag_class, p = .3, list = FALSE)
test <- test#total[train$EVENT_ID %in% c(101183757,101183885,101184013),]
train <- total#[-inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
validation <- total_n[inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
train$flag_class <- ifelse(train$flag_class == 'Y', 1, 0)
test$flag_class <- ifelse(test$flag_class == 'Y', 1, 0)
validation$flag_class <- ifelse(validation$flag_class == 'Y', 1, 0)
feat <- colnames(train)[c(3:(ncol(train)-2))] # train
dtrain <- xgb.DMatrix(as.matrix(train[,feat]), label = train$flag_class)
dtest <- xgb.DMatrix(as.matrix(test[,feat]),label = test$flag_class)
dvalid <- xgb.DMatrix(as.matrix(validation[,feat]),label = validation$flag_class)
watchlist <- list(eval = dvalid, train = dtrain)
inTraining <- createDataPartition(total$flag_class, p = .3, list = FALSE)
setwd('/Users/ivanliu/Google Drive/Melbourne Datathon/Melbourne_Datathon_2015_Kaggle')
rm(list=ls()); gc()
library(xgboost);library(pROC);require(randomForest);library(caret);
load('data/9_train_validation_test_20151122.RData');ls()
# load('data/v5/Ivan_Train_Test_Scale_Center_20151123.RData');
options(scipen=999);set.seed(19890624)
inTraining <- createDataPartition(total$flag_class, p = .3, list = FALSE)
test <- test#total[train$EVENT_ID %in% c(101183757,101183885,101184013),]
train <- total#[-inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
validation <- total_n[inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
train$flag_class <- ifelse(train$flag_class == 'Y', 1, 0)
test$flag_class <- ifelse(test$flag_class == 'Y', 1, 0)
validation$flag_class <- ifelse(validation$flag_class == 'Y', 1, 0)
feat <- colnames(train)[c(3:(ncol(train)-2))] # train
dtrain <- xgb.DMatrix(as.matrix(train[,feat]), label = train$flag_class)
dtest <- xgb.DMatrix(as.matrix(test[,feat]),label = test$flag_class)
dvalid <- xgb.DMatrix(as.matrix(validation[,feat]),label = validation$flag_class)
watchlist <- list(eval = dvalid, train = dtrain)
inTraining <- createDataPartition(total$flag_class, p = .3, list = FALSE)
test <- test#total[train$EVENT_ID %in% c(101183757,101183885,101184013),]
train <- total#[-inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
validation <- total[inTraining,]#total[!train$EVENT_ID %in% c(101183757,101183885,101184013),]
train$flag_class <- ifelse(train$flag_class == 'Y', 1, 0)
test$flag_class <- ifelse(test$flag_class == 'Y', 1, 0)
validation$flag_class <- ifelse(validation$flag_class == 'Y', 1, 0)
feat <- colnames(train)[c(3:(ncol(train)-2))] # train
dtrain <- xgb.DMatrix(as.matrix(train[,feat]), label = train$flag_class)
dtest <- xgb.DMatrix(as.matrix(test[,feat]),label = test$flag_class)
dvalid <- xgb.DMatrix(as.matrix(validation[,feat]),label = validation$flag_class)
watchlist <- list(eval = dvalid, train = dtrain)
# 3. generalized linear model
bst <- xgb.train(
data = dtrain, nround = 350, watchlist = watchlist, objective = "binary:logistic", booster = "gblinear", eta = 0.3,
nthread = 4, alpha = 1e-3, lambda = 1e-6, print.every.n = 10
)
p_glm = predict(bst,dtest)
write.csv(p_glm, paste0('ReadyForBlending/submission/test/xgboost_glm/submission_xgboost_glm_20151128_test.csv'))
